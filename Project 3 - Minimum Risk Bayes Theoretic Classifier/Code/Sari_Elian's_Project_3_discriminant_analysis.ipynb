{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sari275/my-machine-learning-projects/blob/main/Sari_Elian's_Project_3_discriminant_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "d1jvXBfCDRqN"
      },
      "source": [
        "# DISCRIMINANT ANALYSIS\n",
        "\n",
        "In this coding assignment you are to implement a Minimum Risk Bayes Decision Theoretic classifier. Use the training set to train the classifier and the validation set to evaluate the accuracy.\n",
        "\n",
        "Assume the following:\n",
        "1. All conditional density functions are multivariate Gaussian\n",
        "2. Each class has its own covariance matrix\n",
        "3. Equally likely prior probabilities\n",
        "4. 0-1 loss function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d-qRoESDRqP"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5tFsCiqDRqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb1ddff-7754-49d9-b71b-1a3a75ffd243"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import multivariate_normal\n",
        "# Load training data - 135 observations, 4 features, 3 classes,\n",
        "df = pd.read_csv(\"iris_corrupted_training_dataset.csv\")\n",
        "print(df.head())\n",
        "df = df.values\n",
        "training_data = df\n",
        "\n",
        "# Load validation data - 15 samples\n",
        "df = pd.read_csv(\"iris_validation_dataset.csv\")\n",
        "print(df.head())\n",
        "df = df.values\n",
        "validation_data = df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length   sepal_width   petal_length   petal_width   class\n",
            "0        5.7147        2.6743         3.2696       1.65440       2\n",
            "1        5.1734        3.7374         5.9442       3.00050       3\n",
            "2        7.3776        3.1505         3.3543       0.64839       2\n",
            "3        6.4908        2.3983         3.3917       1.54950       2\n",
            "4        6.8182        3.4016         4.7495       0.57970       3\n",
            "   sepal_length   sepal_width   petal_length   petal_width   class\n",
            "0           4.4           2.9            1.4           0.2       1\n",
            "1           6.7           3.0            5.2           2.3       3\n",
            "2           4.9           3.1            1.5           0.2       1\n",
            "3           5.1           2.5            3.0           1.1       2\n",
            "4           6.1           3.0            4.6           1.4       2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data - 135 observations, 4 features, 3 classes\n",
        "df = pd.read_csv(\"iris_corrupted_training_dataset.csv\")\n",
        "training_data = df.values\n",
        "\n",
        "# Load validation data - 15 samples\n",
        "df = pd.read_csv(\"iris_validation_dataset.csv\")\n",
        "validation_data = df.values\n",
        "\n",
        "# Split training data into three classes\n",
        "class_data = {}\n",
        "for c in range(1, 4):\n",
        "    class_data[c] = training_data[training_data[:, -1] == c][:, :-1]\n",
        "\n",
        "# Calculate mean and covariance matrix for each class\n",
        "class_mean = {}\n",
        "class_cov = {}\n",
        "for c in class_data.keys():\n",
        "    class_mean[c] = np.mean(class_data[c], axis=0)\n",
        "    class_cov[c] = np.cov(class_data[c].T)\n",
        "\n",
        "# Define loss function\n",
        "losses = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])\n",
        "\n",
        "# Define function to predict class label\n",
        "def predict(x):\n",
        "    posteriors = []\n",
        "    for c in class_mean.keys():\n",
        "        posterior = (1/3) * multivariate_normal.pdf(x, mean=class_mean[c], cov=class_cov[c])\n",
        "        posteriors.append(posterior)\n",
        "    return np.argmin([np.sum(np.multiply(losses[i], posteriors)) for i in range(3)]) + 1\n",
        "\n",
        "# Make predictions for validation data\n",
        "y_hat = []\n",
        "y = []\n",
        "for sample in validation_data:\n",
        "    prediction = predict(sample[:-1])\n",
        "    y_hat.append(prediction)\n",
        "    y.append(sample[-1])\n",
        "\n",
        "# Print actual and predicted labels\n",
        "print(\"y:   \", y)\n",
        "print(\"y_hat:\", y_hat)\n",
        "\n",
        "# Calculate classification accuracy\n",
        "Avg_class_accuracy = np.mean(np.array(y_hat) == np.array(y))\n",
        "print(\"Average Classification accuracy:\", Avg_class_accuracy)\n"
      ],
      "metadata": {
        "id": "8SNCDq3-nTgq",
        "outputId": "d5312bb8-72d8-4e4c-fdc8-bb677ffadce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y:    [1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0]\n",
            "y_hat: [1, 3, 1, 2, 2, 1, 2, 1, 3, 3, 3, 3, 2, 3, 1]\n",
            "Average Classification accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    }
  ]
}