{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml58PJ9UDwRk"
      },
      "source": [
        "**Principal Component Analysis**\n",
        "\n",
        "You will implement dimensionality reduction with PCA.  \n",
        "\n",
        "1). Read iris_dataset.csv (4 features, hence 4 PCs)\n",
        "\n",
        "2). Find the principal components\n",
        "\n",
        "3). Recontruct the dataset (X_hat)\n",
        "\n",
        "4). Determine the accuracy of X_hat for 1 PC and 4 PCs using LDA classifier (provided below)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3DA-QxT0O6X",
        "outputId": "e1e369a7-7fc3-48b9-ed60-fd46fe8430d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                0           1           2           3           4\n",
            "count  150.000000  150.000000  150.000000  150.000000  150.000000\n",
            "mean     5.843333    3.057333    3.758000    1.199333    2.000000\n",
            "std      0.828066    0.435866    1.765298    0.762238    0.819232\n",
            "min      4.300000    2.000000    1.000000    0.100000    1.000000\n",
            "25%      5.100000    2.800000    1.600000    0.300000    1.000000\n",
            "50%      5.800000    3.000000    4.350000    1.300000    2.000000\n",
            "75%      6.400000    3.300000    5.100000    1.800000    3.000000\n",
            "max      7.900000    4.400000    6.900000    2.500000    3.000000\n",
            "(150, 5)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.decomposition import PCA\n",
        "  \n",
        "# Load data - 150 observations, 4 features, 3 classes, \n",
        "df = pd.read_csv(\"iris_dataset.csv\", header=None)\n",
        "print(df.describe())\n",
        "data = df.values\n",
        "print(np.shape(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J_I64r12CK1",
        "outputId": "3e79beb5-b389-447b-fbb8-ba311221d4a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Average accuracy with the original dataset = 0.9800\n"
          ]
        }
      ],
      "source": [
        "## Setup\n",
        "\n",
        "# Shuffle data randomly\n",
        "shuffled_data = data;\n",
        "np.random.shuffle(shuffled_data)\n",
        "X = shuffled_data[:,0:4]  # 150x4\n",
        "y = shuffled_data[:,4]\n",
        "\n",
        "# Classification accuracy with the original dataset using LDA\n",
        "model_mean_scores = []\n",
        "model = LinearDiscriminantAnalysis().fit(X, y)\n",
        "scores = cross_val_score(model, X, y, cv=10)\n",
        "model_mean_scores.append(np.mean(scores))\n",
        "print('>> Average accuracy with the original dataset = {0:0.4f}'.format(model_mean_scores[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "g3llQ6-RP00N"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy(X_hat, Num_PC, y):\n",
        "    \n",
        "  ###############################################\n",
        "  # Evaluate classificatin accuracy with LDA\n",
        "  ###############################################\n",
        "  '''\n",
        "    Inputs:\n",
        "      X_hat: reconstructed dataset. dimension=150x4\n",
        "      Num_PC: number of PC's used to recover X_hat\n",
        "      y: class label vector. dimension=150x1\n",
        "\n",
        "  '''\n",
        "  \n",
        "\n",
        "\n",
        "  X_train = X_hat[:,0:Num_PC]        # dimensionally reduced dataset\n",
        "  y_train = y\n",
        "\n",
        "  model_mean_scores = []\n",
        "  model = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
        "  scores = cross_val_score(model, X_train, y_train, cv=10)\n",
        "  model_mean_scores.append(np.mean(scores))\n",
        "\n",
        "  print('Average accuracy = {0:0.4f} with {1:1d} PCs'\n",
        "     .format(model_mean_scores[0], Num_PC))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-L8WvJIAKeY",
        "outputId": "e55b7811-6cfd-4349-b459-364e98588873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.36138659 -0.65658877 -0.58202985  0.31548719]\n",
            " [-0.08452251 -0.73016143  0.59791083 -0.3197231 ]\n",
            " [ 0.85667061  0.17337266  0.07623608 -0.47983899]\n",
            " [ 0.3582892   0.07548102  0.54583143  0.75365743]]\n",
            "Reconstruction error with 1 PC is 0.0856\n",
            "Reconstruction error with 4 PCs is 1.5884\n",
            "Average accuracy = 0.9333 with 1 PCs\n",
            "Average accuracy = 0.9800 with 4 PCs\n"
          ]
        }
      ],
      "source": [
        "### Your code goes here ...\n",
        "# PCA with eigen decomposition\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_centered = X - X_mean\n",
        "covariance_matrix = np.cov(X_centered.T)\n",
        "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
        "index = eigenvalues.argsort()[::-1]\n",
        "eigenvectors = eigenvectors[:,index]\n",
        "eigenvalues = eigenvalues[index]\n",
        "Principal_Components = eigenvectors[:,0:4] # Principal components matrix\n",
        "print(Principal_Components)\n",
        "\n",
        "# Reconstruction of the dataset\n",
        "X_hat_1pc = X_centered.dot(Principal_Components[:,0]).reshape(-1,1).dot(Principal_Components[:,0].reshape(1,-1)) + X_mean\n",
        "X_hat_4pc = X_centered.dot(Principal_Components) + X_mean\n",
        "\n",
        "# Reconstruction errors\n",
        "reconstruction_error_1pc = np.mean((X - X_hat_1pc)**2)\n",
        "reconstruction_error_4pc = np.mean((X - X_hat_4pc)**2)\n",
        "print('Reconstruction error with 1 PC is {:.4f}'.format(reconstruction_error_1pc))\n",
        "print('Reconstruction error with 4 PCs is {:.4f}'.format(reconstruction_error_4pc))\n",
        "\n",
        "# Classification accuracy with LDA\n",
        "def evaluate_accuracy(X_hat, Num_PC, y):\n",
        "    X_train = X_hat[:,0:Num_PC]\n",
        "    y_train = y\n",
        "    model_mean_scores = []\n",
        "    model = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=10)\n",
        "    model_mean_scores.append(np.mean(scores))\n",
        "    print('Average accuracy = {:.4f} with {} PCs'.format(model_mean_scores[0], Num_PC))\n",
        "\n",
        "evaluate_accuracy(X_hat_1pc, 1, y) # classification accuracy with 1 PC\n",
        "evaluate_accuracy(X_hat_4pc, 4, y) # classification accuracy with 4 PCs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
